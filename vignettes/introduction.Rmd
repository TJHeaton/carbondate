---
title: "Introduction to carbondate"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to carbondate}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(carbondate)
```

# Introduction

The **carbondate** package contains functions for analysing of multiple related radiocarbon determinations. Due to fluctuations in past radiocarbon (^14^C) levels, calibration is required to convert ^14^C determinations into calendar ages. In many cases, we wish to calibrate a set of samples which are known to be related to one another (for example, arising from a particular site, or set of sites, populated by a particular culture). Each sample has an unknown calendar age but, since they are related, these calendar ages are assumed to arise from the same unknown shared calendar age density. Calibration of the determinations can be improved significantly by incorporating the knowledge that the samples are related.

This package contains functions for both independent calibration of the ^14^C determinations, and two different functions for jointly calibrating related samples.

## Calibration Curve

Given a set of reference objects for which we have both ^14^C measurements and independently known (or estimated) calendar ages, we can create what is known as a calibration curve. This calibration curve is a mapping providing, for an object of true calendar age, the corresponding radiocarbon age. Given a undated object for which we obtain a ^14^C determination one can estimate its calendar age by inverting this mapping. A calibration curve is a required input for all the functions in this package.

The modern, internationally-ratified, standard for the radiocarbon calibration curve is known as IntCal and IntCal20 [@reimer2020] is the current version agreed for use by the community. The curve data `intcal20` is provided in this package. However it is possible to load and use another calibration curve if you wish.

## Example Data

There are some example data sets provided in the package, each of which contain a number of radiocarbon determinations and uncertainties from real-life cases:

-   `kerr`: 255 radiocarbon determinations collated by Kerr and McCormick related to the building and use of raths in Ireland [@kerr2014]

-   `armit`: 2021 radiocarbon determinations collated by Armit et al. from archaeological groups operating in Ireland, to investigate whether a wetter environment around 2700 cal yr BP led to a population collapse [@armit2014]

-   `buchanan`: 628 radiocarbon determinations collated by Buchanan et al. representing the ages of distinct archaeological sites found across Canada and North America during the time of the palaeoindians [@buchanan2008]

# Independent calibration

Although this package is concerned with the calibration of multiple related ^14^C determinations it can be useful to calibrate a single calibration independently, for example for estimating initial values for the sampler, or for comparison. To calibrate a single independent determination (using the provided IntCal20 calibration curve), run the following:

```{r single_calibration}
cal_age_prob = CalibrateSingleDetermination(
  c14_determination = 1413, c14_sigma = 25, intcal20)
plot(
  intcal20$calendar_age, 
  cal_age_prob, 
  type="l", 
  xlab = "Calendar age (yr BP)", 
  ylab = "Probability", 
  xlim=c(1500, 1200),
  yaxt="n")
```

The most common approach to summarise calendar age information of multiple ^14^C determinations is via summed probability distributions (SPD). Here, the posterior calendar age density of each object is first calculated independently from the others as using the function above. These individual densities are then summed/averaged to give an SPD estimate. SPDs are not statistically valid estimators of the calendar age of a potential future object. The independence assumed in the separate calibration of each sample, followed by subsequent summarisation, generates a contradiction. The function is provided her as a useful comparison with the other routines.

To calculate the SPD for a set of radiocarbon determinations (here we use the example dataset `armit`) see the example below, where we also plot the results.

```{r find_spd}
spd = FindSummedProbabilityDistribution(c(1000, 4500), armit$c14_ages, armit$c14_sig, intcal20)
plot(
  spd,
  type="l", 
  xlab = "Calendar age (yr BP)", 
  ylab = "Probability", 
  xlim=c(4500, 1000),
  yaxt="n")
```

Note that the summary functions for plotting the predictive joint calendar age density [described below](#plot_density) can also optionally plot the SPD without having to calculate it separately first.

# Non-parametric calibration of multiple related samples

## Model details

We model our unknown calendar age density $f(\theta)$ as an infinite mixture of individual clusters. These individual calendar age clusters are normal densities that can have different locations and spreads. In some cases, this mix of normal densities may represent true and distinct underlying normal archaeological phases, in which case additional practical inference may be possible. However this is not required for the method to provide good estimation. Each object is then considered to be drawn from one of the (infinite) clusters which constitute the overall $f(\theta)$. The probability that it is drawn from a particular cluster will depend upon the relative weight given to that specific cluster. It will be more likely than an object will come from some clusters than others. Given an object belongs to a particular cluster, its prior calendar age will be normally distributed with the mean and variance of that cluster. The mean and variance of each individual normal cluster that constitutes the overall $f(\theta)$, together with the weightings associated to each cluster, will be estimated based upon the set of ^14^C determinations we observe.

For full technical details of the models used, and explanation of the model parameters, see [@heaton2021].

## Run the sampler

Updating is performed within an overall Gibbs MCMC scheme by sampling the model parameters. There are two different schemes provided to update the DPMM --- a Polya Urn approach [@neal2000] which integrates out the mixing weights of each cluster; and a slice sampling approach in which they are explicitly retained [@walker2007].

To set up with sensible initial values for the sampling parameters, run the following. *[I think we either need more explanation here of what all the different parameters are, or we do not include this part and make it internal to the function - could we discuss which approach would be best?]*

```{r set_parameters}
# Set parameters - Updated adaptive version
# Prior on mu theta for DP - very uninformative based on observed data
initprobs <- mapply(
  CalibrateSingleDetermination,
  kerr$c14_ages,
  kerr$c14_sig,
  MoreArgs = list(calibration_curve=intcal20))
inittheta <- intcal20$calendar_age[apply(initprobs, 2, which.max)]

maxrange <- max(inittheta) - min(inittheta)

# Parameters for sigma2 (sigma^2 ~ InvGamma(nu1, nu2))
# E[tau] = (1/100)^2 Var[tau] = (1/100)^4
# Interval for sigma2 is approx 1/c(nu2/nu1-2*nu2^2/nu1, nu2/nu1+2*nu2^2/nu1)
tempspread <- 0.1 * mad(inittheta)
tempprec <- 1 / (tempspread)^2
nu1 <- 0.25
nu2 <- nu1 / tempprec

lambda <- (100 / maxrange)^2 # Each muclust ~ N(mutheta, sigma2/lambda)
```

We can then run using the Walker method:

```{r calculate_walker, results=FALSE}
walker_temp <- WalkerBivarDirichlet(
  c14_determinations = kerr$c14_ages,
  c14_sigmas = kerr$c14_sig,
  calibration_curve=intcal20,
  lambda = lambda,
  nu1 = nu1,
  nu2 = nu2,
  alpha_shape = 1,
  alpha_rate = 1,
  n_iter = 100,
  n_thin = 5,
  slice_width = max(1000, diff(range(kerr$c14_ages)) / 2),
  slice_multiplier =10,
  n_clust = 10)
```

or the Neal method as follows:

```{r calculate_neal, results=FALSE}
neal_temp <- PolyaUrnBivarDirichlet(
  c14_determinations = kerr$c14_ages,
  c14_sigmas = kerr$c14_sig,
  calibration_curve = intcal20,
  lambda = lambda,
  nu1 = nu1,
  nu2 = nu2,
  alpha_shape = 1,
  alpha_rate = 1,
  n_iter = 100,
  n_thin = 5,
  slice_width = max(1000, diff(range(kerr$c14_ages)) / 2),
  slice_multiplier = 10,
  n_clust = 10)
```

Note this example only runs for 1000 iterations - this is to keep the run time short, but is not enough to lead to a converged results. We suggest running for 100,000 iterations to arrive at the converged results, which are shown in [@heaton2021].

Both of these method will output a list containing the sampler outputs at every $n_{\textrm{thin}}$ iteration, with the values of the model parameters and the calendar ages.

## Post-processing

Our sampler provides three outputs of particular interest.

#### Calendar Ages

As described above, the output data includes the calendar age estimate for each ^14^C sample. We can use this to determine the posterior distribution of the calendar age for each sample. Note that the calendar age estimates use the joint information provided by all the 14C determinations (as opposed to solely the ^14^C determination of the single object that would be found using `CalibrateSingleDetermination`) on the understanding the calendar ages of the objects are related.

You can calculate and plot this using `PlotCalendarAgeDensityIndividualSample` - for example to calculate the posterior calendar age distribution for the 10th ^14^C determination:

```{r plot_individual, out.width="100%", fig.width=10, fig.height=8, cache=TRUE}
PlotCalendarAgeDensityIndividualSample(
  ident = 10,
  c14_determinations = kerr$c14_ages,
  c14_sigmas = kerr$c14_sig,
  calibration_curve = intcal20,
  output_data = walker_temp)
```

#### Density Estimate to Summarise Objects {#plot_density}

The output data contains information to allow calculation of the predictive distribution for the calendar age of a new, as yet undiscovered, object. This density estimate summarises the calendar ages of all objects. It is generated using the posterior sampled values of the DPMM component of our MCMC sampler. This calendar age density can be calculated and plotted using `PlotPredictiveCalendarAgeDensity`.

The function allows calculation using multiple outputs so that their results can be compared. It also, by default, plots the SPD, although this can be suppressed with the argument `show_SPD = FALSE`. For example below we compare the results from the two sampler methods above.

```{r plot_density, out.width="100%", fig.width=10, fig.height=8, cache=TRUE}
densities = PlotPredictiveCalendarAgeDensity(
  c14_determinations = kerr$c14_ages,
  c14_sigmas = kerr$c14_sig,
  calibration_curve = intcal20,
  output_data = list(walker_temp, neal_temp),
  n_posterior_samples = 50,
  denscale = 2.5)
```

#### Number of Clusters

The output data also contains information about the cluster allocation of each sampled object, which we can use to build the probability for there being a given number of total clusters. If we believe the underlying individual clusters in the model have inherent meaning in terms of representing genuine and distinct periods of site usage, as opposed to simply providing a tool to enable a non-parametric density estimate, this information may be archaeologically useful.

```{r plot_clusters, out.width="50%", fig.width=5, fig.height=6, cache=TRUE}
PlotNumberOfClusters(output_data = walker_temp)
```

# References
